\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
% \PassOptionsToPackage{numbers, compress}{natbib}
% before loading nips_2017
%
% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{nips_2017}

\usepackage[final]{nips_2017}

% to compile a camera-ready version, add the [final] option, e.g.:
% \usepackage[final]{nips_2017}

%Pour langue et caract√®res sp√©ciaux
\usepackage[french]{babel} 
\usepackage[T1]{fontenc}
%\usepackage{lmodern}
\usepackage[utf8]{inputenc}

%\usepackage[utf8]{inputenc} % allow utf-8 input
%\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{placeins}


\title{Sur la classification d'√©toiles en fonction de leur spectre d'absorption par apprentissage automatique}

% The \author macro works with any number of authors. There are two
% commands used to separate the names and addresses of multiple
% authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to
% break the lines. Using \AND forces a line break at that point. So,
% if LaTeX puts 3 of 4 authors names on the first line, and the last
% on the second line, try using \AND instead of \And before the third
% author name.

\author{
  Patrice~B\'echard\\
  D\'epartement d'informatique\\
  et de recherche op\'erationelle\\
  Universit\'e de Montr\'eal\\
  Montr\'eal, QC H3T 1J4 \\
  \texttt{patrice.bechard@umontreal.ca} \\
  %% examples of more authors
  \And
  Jean-Pascal~Gu\'evin \\
  D\'epartement de math\'ematiques\\
  et de statistique \\
  Universit\'e de Montr\'eal\\
  Montr\'eal, QC H3T 1J4 \\
  \texttt{jean-pascal.guevin@umontreal.ca} \\
  %% \AND
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
}

\begin{document}
% \nipsfinalcopy is no longer used

\maketitle
\vspace{-0.8cm}
\begin{center}
\textbf{IFT6390 - Fondements de l'apprentissage machine - \today}
\end{center}

\begin{abstract}
La classification de spectres stellaires provenant du \textit{Sloan Digital Sky Survey} a \'et\'e effectu\'ee par trois algorithmes d'apprentissage, soit les machines \`a vecteurs de support, les r\'eseaux de neurones de type perceptron multicouche et les r\'eseaux de neurones convolutifs. Un taux de classification $93.40\%$ a \'et\'e obtenu avec les SVM, $94.41\%$ avec les MLP et $94.57\%$ avec les CNN. Une t\^ache similaire a \'et\'e conduite avec des donn\'ees d'\'electrocardiogramme avec des r\'esultats moins concluants. Les taux de classification obtenus sont de $61.36\%$ pour les SVM, $60.69\%$ pour les MLP et $77.39\%$ pour les CNN.
\end{abstract}

% Introduction
\section{Introduction}

<<<<<<< HEAD
L'exploration de notre univers observable a amen√© les astrophysiciens √† observer et √† cat√©goriser des centaines de milliers d'√©toiles en fonction notamment de leur taille, de leur masse, de leur temp√©rature et de leur composition. Ce processus de classification se fait, entre autre, √† partir du spectre d'absorption des √©toiles qui est une mesure de l'intensit√© du spectre √©lectromagn√©tique √©mis par celles-ci en fonction de la longueur d'onde. Une automatisation efficace de ce processus pourrait par cons√©quent √™tre un grand avantage. Nous proposons donc trois algorithmes de classification d'√©toiles en fonction de leur type spectral √† l'aide de m√©thodes d'apprentissage automatique.  Pour la validation des algorithmes, des donn√©es d'√©lectrocardiogramme, √©tant aussi des donn√©es corr√©l√©es en 1 dimension, seront utilis√©es. Les algorithmes d'apprentissage utilis√©s pour effectuer la classification sont les r√©seaux de neurones de type MLP, les r√©seaux de neurones convolutifs (CNN) ainsi que les machines √† vecteur de support (SVM) √† noyau souple. Les bases de donn√©es ainsi que les algorithmes d'apprentissages utilis√©s sont pr√©sent√©s en d√©tails √† la section \ref{sec:methods} et les r√©sultats obtenus sont pr√©sent√©s √† la section \ref{sec:results}. Les codes et les figures pr√©sent√©es pour l'ensemble du projet sont disponibles en ligne sur GitHub : \url{https://github.com/patricebechard/Machine_learning_IFT6390}.


% Presentation des algorithmes et bases de donnees
\section{M√©thodes}\label{sec:methods}
=======
L'aspect principal du projet consiste en la classification d'Ètoiles en fonction de leur type spectral ‡ l'aide d'algorithmes d'apprentissage. L'exploration de notre univers observable a en effet amenÈ les astrophysiciens ‡ observer et ‡ catÈgoriser des centaines de milliers d'Ètoiles en fonction notamment de leur taille, de leur masse, de leur tempÈrature et de leur composition. Ce processus de classification se fait, entre autre, ‡ partir du spectre d'absorption des Ètoiles, c'est-‡-dire une mesure de l'intensitÈ du spectre ÈlectromagnÈtique Èmis par celles-ci en fonction de la longueur d'onde. Pour la validation des algorithmes, des donnÈes d'Èlectrocardiogramme, Ètant aussi des donnÈes corrÈlÈes en 1 dimension, seront utilisÈes. Les algorithmes d'apprentissage utilisÈs pour effectuer la classification sont les rÈseaux de neurones de type MLP, les rÈseaux de neurones convolutifs (CNN) ainsi que les machines ‡ vecteur de support (SVM). Les bases de donnÈes ainsi que les algorithmes d'apprentissages utilisÈs sont prÈsentÈs en dÈtails ‡ la section \ref{sec:methods} et les rÈsultats obtenus sont prÈsentÈs ‡ la section \ref{sec:results}. Les codes et les figures prÈsentÈes pour l'ensemble du projet sont disponibles en ligne sur GitHub : \url{https://github.com/patricebechard/Machine_learning_IFT6390}.


% Presentation des algorithmes et bases de donnees
\section{MÈthodes}\label{sec:methods}

Les donnÈes utilisÈes pour les spectres d'Ètoiles proviennent de la base de donnÈes \textit{Sloan Digital Sky Survey} (SDSS) \textit{Science Archive Server} (SAS) donnant gratuitement accËs aux observations faites par diffÈrents tÈlescopes. Il est Èvidemment nÈcessaire de traiter les spectres obtenus par le biais du SDSS, ceux-ci Ètant gÈnÈralement trËs bruitÈs. Un processus lissage et de normalisation permet d'en extraire l'information pertinente en Èliminant le plus possible le bruit et en ne conservant que ce qui semble correspondre ‡ des tendances plus globales. De plus, chaque spectre a ÈtÈ tronquÈ de sorte que seul le flux correspondant aux log-longueurs d'onde entre $3.65$ et $3.80$ (correspondant aux longueurs d'onde entre $\approx 398.1$ nm jusqu'‡ $\approx 707.9$ nm, ce qui reprÈsente le spectre de lumiËre visible). Nous avons aplati les spectres en ajustant une courbe de degrÈ 3 aux donnÈes et divisÈ par celle-ci. Finalement, une interpolation linÈaire de points a permis de diminuer le nombre de traits caractÈristiques ‡ 1000, ce que les algorithmes peuvent manipuler sans problËme. Un Èchantillon de 10000 Ètoiles pour chaque 6 types spectral diffÈrent utilisÈ (A, F, G, K, M, WD) a ÈtÈ traitÈ. Puisque ces spectres sont les seules entrÈes des algorithmes essayÈs, le traitement des donnÈes a un impact majeur sur les rÈsultats.  La figure \ref{fig:preprocessing_sdss} prÈsente un exemple d'un spectre d'Ètoile avant et aprËs avoir traiter les donnÈes.
>>>>>>> 6621b0a5e70dc31ef4f0aaecb19bd4515b78d55b

Les donn√©es utilis√©es pour les spectres d'√©toiles proviennent de la base de donn√©es \textit{Sloan Digital Sky Survey} (SDSS) \textit{Science Archive Server} (SAS) donnant gratuitement acc√®s aux observations faites par diff√©rents t√©lescopes. Il est √©videmment n√©cessaire de traiter les spectres obtenus par le biais du SDSS, ceux-ci √©tant g√©n√©ralement tr√®s bruit√©s. Un processus lissage et de normalisation utilisant notamment des moyennes mobiles permet d'en extraire l'information pertinente en √©liminant le plus possible le bruit et en ne conservant que ce qui semble correspondre √† des tendances plus globales. De plus, chaque spectre a √©t√© tronqu√© de sorte que seul la section correspondant aux log-longueurs d'onde entre $3.65$ et $3.80$ -- correspondant aux longueurs d'onde entre $\approx 398.1$ nm jusqu'√† $\approx 707.9$ nm, ce qui repr√©sente le spectre de lumi√®re visible -- a √©t√© conserv√©. Nous avons aplati les spectres en ajustant une courbe de degr√© 3 aux donn√©es et divis√© par celle-ci. Finalement, une interpolation lin√©aire de points a permis de diminuer le nombre de traits caract√©ristiques √† 1000, ce que les algorithmes peuvent manipuler sans probl√®me. Un √©chantillon de 60000 √©toiles r√©parti √©galement pour 6 types spectral diff√©rents utilis√©s (A, F, G, K, M, WD) a √©t√© trait√©. Puisque ces spectres sont les seules entr√©es des algorithmes essay√©s, le pr√©traitement des donn√©es a un impact majeur sur les r√©sultats. La figure \ref{fig:preprocessing_sdss} pr√©sente un exemple d'un spectre d'√©toile avant et apr√®s avoir subi le processus de pr√©traitement. Ce processus est impl√©ment√© par le module \texttt{sdss\_preprocess\_data} qui permet √©galement d'extraire les donn√©es directement de SDSS.

\begin{figure}[!htb]
 \begin{minipage}{0.45\textwidth}
   \includegraphics[width=\linewidth]{figures/sdss_raw.png}
 \end{minipage}\
 $\xRightarrow{\text{preprocessing}}$
 \begin{minipage}{0.45\textwidth}
   \includegraphics[width=\linewidth]{figures/sdss_norm.png}
 \end{minipage}\
 \caption{Effet du pr√©traitement des spectres d'√©toiles. √Ä gauche, un exemple de donn√©es brutes fournies par le \textit{Sloan Digital Sky Survey} est pr√©sent√©. √Ä droite, le m√™me exemple a √©t√© normalis√© et liss√©.}\label{fig:preprocessing_sdss}
\end{figure}

Une premi√®re validation des algorithmes est effectu√©e par le biais d'une t√¢che connexe, soit la classification d'√©lectrocardiogrammes selon l'√©tat de sant√© du patient duquel il provient. Les √©lectrocardiogrammes (ECG) √©tant fort semblables dans leurs formes √† des spectres d'√©toiles (tous deux √©tant des donn√©es corr√©l√©es dans l'espace en 1 dimension), ceci permet un premier ajustement des algorithmes en plus de nous initier au fonctionnement de ceux-ci dans le contexte d'une analyse spectroscopique. Les √©lectrocardiogrammes utilis√©s proviennent du \textit{PhysioNet/Computing in Cardiology Challenge 2017} et ont l'avantage d'√™tre plus simple √† analyser, puisqu'ils sont plus lisses et moins bruit√©s. Une s√©quence de 10 secondes a √©t√© conserv√©e pour chaque ECG et les s√©quences ont √©t√© class√©es en 2 cat√©gories, soit un patient en sant√© (5050 exemples), soit un patient avec une arythmie ou un autre probl√®me cardiaque (3478 exemples). Le nombre de traits caract√©ristiques pour cet ensemble de donn√©es est de 500 pour chaque exemple. Le pr√©traitement des donn√©es est impl√©ment√© par le module \texttt{ecg\_preprocess\_data}.

Trois familles d'algorithmes seront √©tudi√©es dans le cadre de ce projet. Tout d'abord, nous utiliserons des r√©seaux de neurones de type perceptron multicouche (MLP). L'usage de librairies telles Keras ou TensorFlow rend tr√®s simple l'impl√©mentation de ce type d'algorithme. Le r√©seau cr√©√© prendra en entr√©e un spectre trait√© (centr√©, r√©duit et liss√©) et retournera en sortie la classification du spectre selon un encodage \textit{onehot}. La m√©thodologie utilis√©e pour ajuster les hyperparam√®tres (nombre de couches cach√©es, nombre de neurones dans chaque couche, r√©gularisation, taille des lots) consiste √† faire un \textit{grid search} sur plusieurs architectures de r√©seaux ainsi que plusieurs types de r√©gularisation et plusieurs tailles de lots pour trouver une ou plusieurs combinaisons prometteuses en mesurant l'erreur de classification sur l'ensemble de validation. Un processus de \textit{fine tuning} des param√®tres suivait ensuite pour am√©liorer le plus possible l'efficacit√© de l'algorithme. Finalement, un r√©entra√Ænement sur l'ensemble d'entra√Ænement ainsi que l'ensemble de validation avait lieu, accompagn√© d'un test sur l'ensemble de test nous a permis d'obtenir les r√©sultats finaux. Une pr√©sentation en d√©tails des r√©sultats obtenus est faite √† la section \ref{sec:results}. L'utilisation d'un processeur graphique (GPU) nous a permis d'effectuer une panoplie de diff√©rentes exp√©riences sans que celles-ci soient trop co√ªteuses en temps. Des travaux similaires ont √©t√© men√©s par \cite{bailer1998automated} ainsi que \cite{carricajo2004automatic} pour les spectres stellaires, et par \cite{shensheng2017deep} pour les √©lectrocardiogrammes.

Ensuite, puisque les points formant un spectre sont corr√©l√©s entre eux, les r√©seaux de neurones convolutifs (CNN) sont une approche d'apparence prometteuse. Le r√©seau cr√©√© calculera des convolutions unidimensionnelles sur les spectres. Le nombre de convolutions, de \textit{feature maps} ainsi que le type de \textit{pooling} (max, moyen, etc.) souhait√©s sont les hyperparam√®tres √† d√©terminer. Ce type d'algorithme permet de r√©duire le nombre de dimensions du probl√®me en plus de prendre en compte des caract√©ristiques des entr√©es comme la connectivit√© locale des traits caract√©ristiques, tout en introduisant une invariance des traductions locales gr√¢ce au \textit{pooling}. \cite{hala2014spectral} a men√© des travaux similaires pour les spectres d'√©toiles. Plusieurs travaux de recherche, notamment par \cite{rajpurkar2017cardiologist} ainsi que \cite{zihlmann2017convolutional} se sont pench√©s sur la classification d'√©lectrocardiogrammes √† l'aide de r√©seaux de neurones convolutifs.

Enfin, les machines √† vecteur de support (SVM) √† noyau souple seront le dernier type d'algorithme d'apprentissage utilis√© pour la classification des spectres stellaires ainsi que des √©lectrocardiogrammes. Ce genre d'algorithme a tendance √† bien se d√©brouiller avec des entr√©es poss√©dant un grand nombre de traits caract√©ristiques. Le noyau √† utiliser sera d√©termin√© lors de la s√©lection du mod√®le. L'impl√©mentation des SVM a √©t√© effectu√©e √† l'aide de la librairie Scikit Learn. Des travaux similaires ont √©t√© men√©s par \cite{bu2014stellar} pour la classification de spectres d'√©toile et par \cite{shensheng2017deep} pour les √©lectrocardiogrammes.

<<<<<<< HEAD


% Resultats

\section{Pr√©sentation des r√©sultats}\label{sec:results}

=======
Trois familles d'algorithmes seront ÈtudiÈes dans le cadre de ce projet. Tout d'abord, nous utiliserons des rÈseaux de neurones de type perceptron multicouche (MLP). L'usage de librairies telles Keras ou TensorFlow rend trËs simple l'implÈmentation de ce type d'algorithme. Le rÈseau crÈÈ prendra en entrÈe un spectre traitÈ (centrÈ, rÈduit et lissÈ) et retournera en sortie la classification du spectre selon un encodage \textit{onehot}. La mÈthodologie utilisÈe pour ajuster les hyperparamËtres (nombre de couches cachÈes, nombre de neurones dans chaque couche, rÈgularisation, taille des lots) consiste ‡ faire un \textit{grid search} sur plusieurs architectures de rÈseaux ainsi que plusieurs types de rÈgularisation et plusieurs tailles de lots pour trouver une ou plusieurs combinaisons prometteuses en mesurant l'erreur de classification sur l'ensemble de validation. Un processus de \textit{fine tuning} des paramËtres suivait ensuite pour amÈliorer le plus possible l'efficacitÈ de l'algorithme. Finalement, un rÈentraÓnement sur l'ensemble d'entraÓnement ainsi que l'ensemble de validation avait lieu, accompagnÈ d'un test sur l'ensemble de test nous a permis d'obtenir les rÈsultats finaux. Une prÈsentation en dÈtails des rÈsultats obtenus est faite ‡ la section \ref{sec:results}. L'utilisation d'un processeur graphique (GPU) nous a permis d'effectuer une panoplie de diffÈrentes expÈriences sans que celles-ci soient trop co˚teuses en temps. Des travaux similaires ont ÈtÈ conduits par \cite{bailer1998automated} ainsi que \cite{carricajo2004automatic} pour les spectres stellaires, et par \cite{shensheng2017deep} pour les Èlectrocardiogrammes.

Ensuite, puisque les points formant un spectre sont corrÈlÈs entre eux, les rÈseaux de neurones convolutifs (CNN) sont une approche qui semble prometteuse. Le rÈseau crÈÈ calculera des convolutions unidimensionnelles ‡ partir des donnÈes. Le nombre de convolutions, de filtres ainsi que le type de \textit{pooling} (max, moyen, etc.) souhaitÈs sont les hyperparamËtres ‡ dÈterminer. Ce type d'algorithme permet de rÈduire le nombre de dimensions du problËme en plus de prendre en compte des caractÈristiques des entrÈes comme la connectivitÈ locale des traits caractÈristiques, tout en introduisant une invariance des traductions locales gr‚ce au \textit{pooling}. \cite{hala2014spectral} a conduit des travaux similaires pour les spectres d'Ètoiles. Plusieurs travaux de recherche, notamment par \cite{rajpurkar2017cardiologist} ainsi que \cite{zihlmann2017convolutional} se sont penchÈs sur la classification d'Èlectrocardiogrammes ‡ l'aide de rÈseaux de neurones convolutifs.

Enfin, les machines ‡ vecteur de support (SVM) seront le dernier type d'algorithme d'apprentissage utilisÈ pour la classification des spectres stellaires ainsi que des Èlectrocardiogrammes. Ce genre d'algorithme a tendance ‡ bien se dÈbrouiller avec des entrÈes possÈdant un grand nombre de traits caractÈristiques. Le noyau ‡ utiliser sera dÈterminÈ lors de la sÈlection du modËle. De plus, pour la t‚che de classification multiclasse des spectres stellaires, le choix du type de comparaison pour les frontiËres de dÈcision (\textit{one-vs-one} ou \textit{one-vs-rest}) sera ‡ dÈterminer. L'implÈmentation des SVM a ÈtÈ conduite ‡ l'aide de la librairie Scikit Learn. Des travaux similaires ont ÈtÈ conduits par \cite{bu2014stellar} pour la classification de spectres d'Ètoile et par \cite{shensheng2017deep} pour les Èlectrocardiogrammes.

>>>>>>> 6621b0a5e70dc31ef4f0aaecb19bd4515b78d55b

%%%%%%%%% ELECTROCARDIOGRAMMES


\subsection{√âlectrocardiogrammes}

Contrairement √† ce √† quoi nous nous attendions, nous avons eu beaucoup plus de probl√®mes avec les donn√©es d'√©lectrocardiogramme qu'avec les donn√©es de spectres stellaires. Tout d'abord, pour les SVM, des tests ont √©t√© effectu√©s pour d√©terminer le noyau du SVM √† utiliser parmi ceux impl√©ment√©s par d√©faut dans Scikit Learn. Nous avons conserv√© le noyau mou de type polynomial (\texttt{poly}, $(\gamma\langle~x,~x'~\rangle~+~r)^d$) et un noyau √† fonction √† base radiale (\texttt{rbf}, ~$\exp(-\gamma||x-x'||_2 ^2)$). D'autres noyaux (lin√©aire, sigmoid) ont √©galement √©t√© test√©s, mais le faible taux de succ√®s obtenu les ont rapidement discr√©dit√©s. L'effet de trois hyperparam√®tres a √©t√© √©tudi√© pour cet algorithme: le noyau utilis√©, le degr√© du polyn√¥me dans le cas d'un noyau polynomial et la valeur de la constante de r√©gularisation $C$ puisqu'il s'agit d'un \textit{soft kernel} SVM. La table~\ref{tab:ecg_preprocessing} montre les taux de classification obtenus pour ces hyperparam√®tres.

Contrairement ce ‡ quoi nous nous attendions, nous avons eu beaucoup plus de problËmes avec les donnÈes d'Èlectrocardiogramme qu'avec les donnÈes de spectres stellaires. Tout d'abord, pour les SVM, des tests ont ÈtÈ effectuÈs pour dÈterminer le noyau du SVM ‡ utiliser parmi ceux implÈmentÈs par dÈfaut dans Scikit Learn, soit un noyau linÈaire(\texttt{linear}, $\langle x, x'\rangle$), un noyau ‡ fonction ‡ base radiale (\texttt{rbf}, $\exp(-\gamma||x-x'||_2 ^2)$) avec un facteur $\gamma$ ‡ dÈterminer, un noyau polynomial (\texttt{poly}, $(\gamma\langle x, x' \rangle + r)^d$) avec des facteurs $\gamma$ et $r$ ‡ dÈterminer, ou un noyau sigmoÔdal (\texttt{sigmoid}, $\tanh (\gamma\langle x, x' \rangle + r)$). Les rÈsultats obtenus pour ces noyaux avec leurs valeurs par dÈfaut sont prÈsentÈs au tableau \ref{tab:ecg_svm_kernel}.

\begin{table*}[htb]
  \caption{RÈsultats pour la classification d'Èlectrocardiogrammes en fonction du noyau utilisÈ.}
  \vspace{0.2cm}
  \label{tab:ecg_svm_kernel}
  \centering
  \begin{tabular}{lllll}
    \toprule
    \sc{Noyau} & \texttt{linear} & \texttt{rbf} & \texttt{poly} & \texttt{sigmoid} \\
    \midrule
    \sc{PrÈcision}  & 55.06\% & 59.28\% & 55.06\% & 52.60\% \\
    \bottomrule
  \end{tabular}
\end{table*}

…tant donnÈ les rÈsultats obtenus, on dÈcide de ne garder que le noyau \texttt{rbf} pour simplifier la suite. Ces rÈsultats Ètant trËs bas, il est pertinent de se questionner sur la validitÈ du prÈtraitement des donnÈes pour notre problËme. Tout d'abord, nous essaierons de rÈduire la dimensionnalitÈ des donnÈes ‡ l'aide d'analyse de composantes principales (PCA) sur les donnÈes normalisÈes, similairement ‡ \cite{polat2007detection}. De plus, puisque les Èlectrocardiogrammes sont des donnÈes pÈriodiques, nous essaierons dans un autre cas d'effectuer une transformÈe de Fourier sur les donnÈes normalisÈes et regarder si l'une de ces mÈthodes diminue l'erreur de classification. Ce type de prÈtraitement a ÈtÈ utilisÈ conjointement avec des rÈseaux de neurones prÈcÈdemment, notamment par \cite{gothwal2011cardiac}. Les figures \ref{fig:ecg_pca} et \ref{fig:ecg_fourier} (en annexe) prÈsentent les courbes d'apprentissage obtenues pour un SVM avec noyau RBF.

Finalement, en utilisant un CNN pour faire la dÈtection d'arythmies cardiaques, nous avons essayÈ plusieurs configurations pour maximiser la classification. En mettant un CNN et un rÈseau MLP complËtement connectÈ bout-‡-bout, nous avons vÈrifiÈ l'erreur de classification en faisant varier le nombre de couches de convolution et de pooling, ainsi qu'en essayant diverses architectures pour le MLP. Nous nous sommes limitÈs ‡ des tailles de filtres de convolution de largeur 4 et des filtres de pooling de largeur 4. Nous n'avons pas jugÈ nÈcessaire de tester le CNN avec les donnÈes prÈtraitÈes ‡ l'aide de PCA ou d'une transformation de Fourier.

Les rÈsultats finaux de la prÈcision de chaque algorithms sur les Èlectrocardiogrammes est prÈsentÈ au tableau \ref{tab:ecg_final_results}.

\begin{table*}[htb]
<<<<<<< HEAD
  \caption{Taux de classification obtenu avec l'algorithme SVM pour les trois noyaux √©tudi√©s en terme du param\'etre de p\'enalit\'e $C$.}
  \vspace{0.2cm}
  \label{tab:ecg_preprocessing}
  \centering
  \begin{tabular}{lllllll}
    \toprule
    & \multicolumn{3}{c}{\sc{Ens. d'entra√Ænement}} & \multicolumn{3}{c}{\sc{Ens. de validation}}\\
    \sc{Noyau} & $C=0.75$ & $C=1.0$ & $C=1.25$ & $C=0.75$ & $C=1.0$ & $C=1.25$ \\
    \midrule
    RBF          & 74.42\% & 85.68\% & 91.24\% & 59.68\% & 60.24\% & 59.61\% \\
    Poly. deg. 2 & 85.29\% & 89.45\% & 91.73\% & 61.08\% & 61.37\% & 60.94\% \\
    Poly. deg. 3 & 93.39\% & 98.03\% & 98.84\% & 59.68\% & 58.13\% & 56.09\% \\
=======
  \caption{RÈsultats pour la classification d'Èlectrocardiogrammes}
  \label{tab:ecg_final_results}
  \centering
  \begin{tabular}{llll}
    \toprule
    \sc{Algorithme}     & SVM     & RÈseau de neurones MLP & CNN \\
    \midrule
    \sc{PrÈcision} & \%  & \%   & \%  \\

>>>>>>> 6621b0a5e70dc31ef4f0aaecb19bd4515b78d55b
    \bottomrule
  \end{tabular}
\end{table*}

<<<<<<< HEAD
On note d'abord √† quel point cet algorithme appliqu√© √† cet ensemble de donn√©es est √† risque de sur-apprentissage. En effet, pour chacun des noyaux, le taux classifications atteint $90\%$ et plus d√®s que $C\geq1$. Pourtant, pour des valeurs de $C$ √† peine inf√©rieure √† 1, on est clairement en pr√©sence de sous-apprentissage, d'autant plus que les matrices de confusions montrent que tous les √©l√©ments sont class√©s dans la m√™me cat√©gorie. L'√©troitesse de la fen√™tre entre ces deux p√¥les √† √©viter s'explique par la faible de taille de l'ensemble d'entra√Ænement. Il appara√Æt √©vident que nous aurions davantage de latitude pour l'entra√Ænement des param√®tres si nous √©tions en possession d'un plus grand nombre de donn√©es. Des propositions permettant de contourner seront discut√©s √† la section~\ref{sec:conclusion}. Il est aussi pertinent de se questionner sur la validit√© du pr√©traitement des donn√©es pour notre probl√®me.

Une premi√®re tentative de diminuer le risque de sur-apprentissage est d'utiliser la technique d'analyse des composantes principales (PCA) afin de diminuer la dimension des traits caract√©ristiques, similairement √† \cite{polat2007detection}. Les tables~\ref{tab:ecg_pca_300} et \ref{tab:ecg_pca_100} montrent les taux de classification obtenus lorsque les 300 et les 100 premi√®res composantes principales sont conserv√©es. L'hypoth√®se √©tait qu'une diminution du nombre de traits caract√©ristiques diminuerait le nombre de param√®tre du SVM √©galement, ce qui devrait r√©sulter en une baisse de la capacit√© du SVM. Le m√™me ph√©nom√®ne que sans l'usage de PCA se produit cependant: on passe de sous-apprentissage √† sur-apprentissage sans que le taux de classification de l'ensemble de validation n'augmente.

Une derni√®re tentative d'am√©liorer les r√©sultats est d'appliquer aux donn√©es une transform√©e de Fourier. En effet, puisque les donn√©es repr√©sentent un signal, il pourrait √™tre avantageux d'√©tudier les fr√©quences principales de ce signal plut√¥t que le signal lui-m√™me. Une d√©marche similaire a √©t√© conduite par \cite{gothwal2011cardiac} pour pr√©traiter les entr√©es d'un r√©seau de neurones. La figure ~\ref{fig:ecg_val_c} en annexe montre les taux de classification obtenus pour le noyau polynomial de degr√© 2 pour diff√©rentes valeurs de $C$. La table \ref{tab:ecg_fourier} montre le taux de classification pour les diff√©rents noyaux. L'exact m√™me ph√©nom√®ne se reproduit cependant: l'algorithme passe du sous-apprentissage au sur-apprentissage sans que l'erreur de classification de l'exemple de validation ne diminue. La figure~\ref{fig:ecg_val_c} illustre cela: on y voit que le taux de bonnes classifications augmente pour l'ensemble d'entra√Ænement, mais pas pour l'ensemble de validation.

On conclue que le meilleur classeur SVM √† noyau \textit{soft} est celui envoyant tous les √©lectrocardiogrammes √† la m√™me classe, ce qui est le cas pour le noyau polynomial de degr√© 2 et pour le noyau de type RBF pour $C=1$. C'est deux classeurs obtiennent des r√©sultats d'environ $60\%$ sur l'ensemble test, ce qui est seulement d√ª √† la r√©partition des √©lectrocardiogrammes dans les classes sain et malade. Le r√©sultat d'un tel classeur aurait √©t√© de $50\%$ si les r√©partitions avaient √©t√© √©gales. On conclue que le SVM s'applique mal √† cet ensemble de donn√©es puisqu'il s'av√®re incapable de g√©n√©raliser ses r√©sultats. Notons que l'impl√©mentation du SVM pour les donn√©es ECG est effectu√©e dans \texttt{ecg\_svm}.

Des r√©sultats similaires ont √©t√© obtenus avec les r√©seaux de neurones de type MLP. Pour l'ensemble des r√©seaux de neurones de ce rapport, l'optimiseur \textit{Adam} a √©t√© utilis√©, la fonction d'activation ReLU a √©t√© utilis√©e dans le r√©seau et la fonction softmax a √©t√© utilis√©e √† la sortie. Apr√®s un \textit{grid search} sur plusieurs architectures diff√©rentes, nous avons trouv√© une architecture de r√©seau poss√©dant deux couches cach√©es de 250 et 100 neurones, respectivement. Nous avons utilis√© comme entr√©e des neurones les donn√©es pr√©trait√©es normalement (normalis√©es) ainsi que les donn√©es apr√®s y avoir effectuer une transform√©e de Fourier. Nous avons utilis√© un terme de r√©gularisation $\lambda$ de $0.0005$ pour une r√©gularisation de type $L_1$ et $L_2$. La courbe d'apprentissage en fonction du nombre d'√©poques est pr√©sent√© √† la figure \ref{fig:ecg_dnn_train} en annexe. Comme on le voit, l'impl√©mentation utilisant les donn√©es trait√©es par transform√©e de Fourier ont peine √† d√©passer $60\%$ de taux de classification, alors que celles utilisant les donn√©es normalis√©es atteignent √† peine $58\%$, alors qu'il classe tous les exemples dans la m√™me cat√©gorie. Le module \texttt{ecg\_mlp} impl√©mente les r√©seaux de neurones pour les donn√©es ECG.

Finalement, en utilisant un CNN pour faire la d√©tection d'arythmies cardiaques, nous avons essay√© plusieurs configurations pour maximiser la classification. En mettant un CNN et un r√©seau MLP compl√®tement connect√© bout-√†-bout, nous avons v√©rifi√© l'erreur de classification en faisant varier le nombre de couches de convolution et de pooling. Nous avons gard√© le MLP constant d'exp√©rience en exp√©rience avec une couche cach√©e de 50 neurones. Nous nous sommes limit√©s √† des tailles de fen√™tres de convolution de largeur 4 et des filtres de pooling de largeur 4. Nous n'avons pas jug√© n√©cessaire de tester le CNN avec les donn√©es pr√©trait√©es √† l'aide de PCA ou d'une transformation de Fourier. Le taux de classification sur l'ensemble de validation en fonction du nombre de convolutions est r√©sum√© au tableau \ref{tab:n_conv_ecg} en annexe. Notons que ces r√©sultats correspondent au nombre optimal d'√©poques d'entra√Ænement pour chaque combinaison d'hyperparam√®tres. Ceci sera √©galement le cas pour tous les tableaux pr√©sentant des r√©sultats des MLP et des CNN discut√©s dans cet article.


L'√©volution de l'apprentissage en fonction du nombre d'√©poques d'entra√Ænement pour le r√©seau convolutionnel avec 4 convolutions pr√©sent√© au tableau \ref{tab:n_conv_ecg} test√© sur l'ensemble de test est pr√©sent√© √† la figure \ref{fig:ecg_cnn_train}. Le module \texttt{ecg\_cnn} impl√©mente les CNN pour les donn√©es ECG.

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=0.6\textwidth]{figures/ecg_cnn_train.png}
\caption{Taux de classification sur les donn√©es d'√©lectrocardiogramme en fonction du nombre d'√©poques d'entra√Ænement pour le r√©seau de neurones convolutif avec 4 convolutions. }
\label{fig:ecg_cnn_train}
\end{center}
\end{figure}


Les r√©sultats finaux de la pr√©cision de chaque algorithmes sur les √©lectrocardiogrammes sont pr√©sent√©s au tableau \ref{tab:ecg_final_results}. Les r√©sultats pr√©sent√©s sont ceux pour lesquels les meilleurs r√©sultats ont √©t√© obtenus.

\begin{table*}[htb]
  \caption{R√©sultats pour la classification d'√©lectrocardiogrammes sur l'ensemble de test pour chaque algorithme utilis√©.}
  \vspace{0.2cm}
  \label{tab:ecg_final_results}
=======

\subsection{Spectres d'Ètoiles}

Les rÈsultats obtenus pour la classification de spectres stellaires ont ÈtÈ beaucoup plus concluants que ceux obtenus pour la classification d'Èlectrocardiogrammes.

\begin{table}[htb]
  \caption{RÈsultats pour la classification de spectres d'Ètoiles}
  \label{tab:star_table}
>>>>>>> 6621b0a5e70dc31ef4f0aaecb19bd4515b78d55b
  \centering
  \begin{tabular}{llll}
    \toprule
    \sc{Algorithme}     & SVM     & MLP & CNN \\
    \midrule
    \sc{Pr√©cision} & 61.37\%  & 60.69\%   & 77.39\%  \\
    \bottomrule
  \end{tabular}
\end{table*}

Comme attendu, on remarque que le taux de classification des CNN est de plus de 16\% plus √©lev√© que celui obtenu avec les autres algorithmes. Cette situation avait √©t√© anticip√©e, puisque les traits caract√©ristiques des signaux d'√©lectrocardiogrammes sont autocorr√©l√©es.


%%%%%%%%%%%%%% SDSS


\subsection{Spectres d'√©toiles}

Les r√©sultats obtenus pour la classification de spectres stellaires ont √©t√© beaucoup plus concluants que ceux obtenus pour la classification d'√©lectrocardiogrammes. Tout d'abord, avec les SVM, nous avons s√©lectionn√© un noyau RBF, puis avons essay√© plusieurs valeurs pour la constante de p√©nalit√© $C$. Les r√©sultats obtenus sont pr√©sent√©s √† la figure \ref{fig:sdss_svm_c} en annexe. On voit que la constante $C$ a un effet important sur les r√©sultats obtenus, et que la valeur optimale de $C$ s'av√®re √™tre 10. Le module \texttt{sdss\_svm} impl√©mente le SVM pour les donn√©es de SDSS.

Pour les r√©seaux de neurones, nous avons essay√© plusieurs architectures au hasard et avons aussi modifier la taille des lots et la r√©gularisation pour l'apprentissage. Encore une fois, les non-lin√©arit√©s choisies dans le r√©seau √©taient de type {ReLU} et celles √† la sortie √©taient de type \textit{softmax}. La table \ref{tab:sdss_dnn_arch} en annexe pr√©sente le taux de classification obtenu pour diff√©rentes architectures de r√©seau de neurones. L'effet de l'architecture sur le taux d'apprentissage √©tait minime, ne faisant varier celui-ci que par moins de 1\% √† taille de lot constant (50) et sans r√©gularisation. Les r√©sultats de classification d√©pendent donc davantage du \textit{seed} que de ces hyperparam√®tres.

Le second hyperparam√®tre √† ajuster pour r√©gler la capacit√© du mod√®le est la taille des lots. Pour le MLP avec les couches cach√©es $[150,100,50]$, plusieurs tailles de lots ont √©t√© test√©es et les r√©sultats sont rapport√©s √† la table \ref{tab:sdss_dnn_batch}. Encore une fois, le taux de classification ne varie que de tr√®s peu pour diff√©rentes tailles de lots.  Finalement, nous avons essay√© plusieurs types de r√©gularisations pour le m√™me r√©seau de neurones. La figure \ref{fig:sdss_dnn_reg} pr√©sente l'effet de la r√©gularisation sur le taux de classification maximale. Les r√©sultats obtenus gr√¢ce √† la r√©gularisation n'ont pas non plus eu beaucoup d'influence sur le taux de classification. 

Une courbe d'apprentissage pour la configuration optimale du MLP est pr\'esent\'ee \`a la figure \ref{fig:sdss_dnn_train}. Les r√©seaux de neurones sont impl√©ment√©s pour les donn√©es de SDSS par le module \texttt{sdss\_mlp}.

Enfin, un algorithme de type r√©seau de neurones convolutif √† √©t√© √©tudi√© pour l'ensemble de donn√©es SDSS. Les hyperparam√®tres √©tudi√©s sont le nombre de convolution ainsi que le nombre de \textit{feature maps}, le \textit{batch size} et le nombre de couches cach√©es ainsi que le nombre de neurones les composant du r√©seau de neurones transmettant le vecteur de sortie du CNN √† la sortie du r√©seau. Mentionnons √©galement qu'un \textit{max pooling} est effectu√© apr√®s chaque convolution.

D'abord, le nombre de convolutions effectu√©es √† √©t√© √©tudi√© pour des nombres variables de \textit{feature maps}. Pour ces essais, le r√©seau de neurone √† la sortie du CNN a √©t√© gard√© identique avec une couche cach√©e de taille 10 et fonctions d'activation ReLU et softmax. Les \textit{batch size} sont √©galement demeur√©s constant √† 50. La table~\ref{tab:sdss_cnn_conv} en annexe montre les taux de classifications obtenus pour l'ensemble de validation pour quelques unes de ces combinaisons. Les r√©sultats obtenus sont relativement similaires, mais tentons d'optimiser les autres hyperparam√®tres pour la configuration [10, 50].

Essayons diff√©rents \textit{batch size} afin de pouvoir observer l'effet de cet hyperparam√®tre. La table~\ref{tab:sdss_cnn_bs} en annexe montre les r√©sultats obtenus pour des \textit{batch size} de respectivement 5, 50 et 500. On voit que le choix des \textit{batch size} n'a que peu d'influence sur le taux de classification. N√©anmoins, puisque ce sont des \textit{batch size} de 50 qui donnent de (l√©g√®rement) meilleurs r√©sultats, prenons cette valeur pour la suite des choses.

Enfin, optimisons la taille de la couche cach√©e du r√©seau de neurone en sortie du CNN. Les architectures consid√©r√©es sont celles se trouvant √† la table~\ref{tab:sdss_cnn_dnn} en annexe. Encore une fois, on voit qu'il n'y a que tr√®s peu de diff√©rence entre les diff√©rentes valeurs de ces hyperparam√®tres. On note cependant que c'est une seule couche cach√©e de taille 50 qui a donn√© les meilleurs r√©sultats. La courbe d'apprentissage du CNN pour les param\`etres optimaux choisis est pr\'esent\'ee \`a la figure \ref{fig:sdss_cnn_train}. On remarque que l'apprentissage pour le CNN est beaucoup plus lisse que pour le MLP.

Concluons cette analyse en notant que les hyperparam√®tres n'avaient pratiquement aucun effet sur les taux de classification obtenus. Cela signifie probablement que l'ensemble de donn√©es est en g√©n√©ral tr√®s facile √† classer. On peut imaginer que les donn√©es forment des \textit{clusters} bien d√©finis dans l'espace des traits caract√©ristiques sauf pour environ 5\% des spectres qui se m√©langent √† des \textit{clusters} d'une autre classe que la leur. Il est donc facile d'obtenir environ 94\% de bonnes classifications sur un ensemble test, mais il serait tr√®s ardu d'obtenir davantage. On remarque √©galement que le taux classification pour l'ensemble d'entra√Ænement, bien que plus √©lev√© que celui de l'ensemble de validation, n'a jamais atteint 100\%, ce qui est coh√©rent avec l'hypoth√®se propos√©e. Le module \texttt{sdss\_cnn} impl√©mente les CNN pour les donn√©es de SDSS.

Les r√©sultats finaux de la pr√©cision de chaque algorithme sur les spectres stellaires sont pr√©sent√©s au tableau \ref{tab:sdss_final_results}. On voit que les algorithmes permettent une meilleure g\'en\'eralisation pour de nouveaux exemples comparativement aux r\'esultats obtenus plut t\^ot pour la classification d'\'electrocardiogrammes. 


\begin{table*}[htb]
  \caption{R√©sultats pour la classification de spectres d'√©toiles sur l'ensemble de test pour chaque algorithme utilis√©.}
  \vspace{0.2cm}
  \label{tab:sdss_final_results}
  \centering
  \begin{tabular}{llll}
    \toprule
    \sc{Algorithme}     & SVM     & MLP & CNN \\
    \midrule
    \sc{Pr√©cision} & 93.40\%  & 94.41\%   & 94.57\%  \\
    \bottomrule
  \end{tabular}
\end{table*}

% Discussion et conclusion
\section{Conclusion}\label{sec:conclusion}

En somme, nous avons classifier des \'etoiles en fonction de leur type spectral en utilisant les spectres de ces \'etoiles comme entr\'ee pour nos algorithmes. Nous avons conduit une exp\'erence similaire pour des \'electrocardiogrammes, donnant cependant des r\'esultats beaucoup moins concluants. Un taux de classification $93.40\%$ a \'et\'e obtenu en utilisant les SVM, $94.41\%$ avec les MLP et $94.57\%$ avec les CNN lors de la classification des \'etoiles. Les scores \'etaient plut\^ot de $61.36\%$ pour les SVM, $60.69\%$ pour les MLP et $77.39\%$ pour les CNN pour la classification d'\'electrocardiogrammes. 

Pour am\'eliorer le score de classification obtenu pour la classification d'\'electrocardiogrammes, il serait pertinent dans une exp\'erience future d'impl\'ementer les m\'ethodes de \textit{cross-validation} ou la technique de \textit{bootstrap} pour que les diff\'erents algorithmes puissent mieux g\'en\'eraliser avec le nombre d'exemples disponibles dans la base de donn\'ees. \'Evidemment, une base de donn\'ees plus volumineuse permettrait de diminuer le risque de sur-entra\^inement.

Finalement, il serait int\'eressant dans des exp\'eriences futures d\'utiliser les spectres stellaires afin de pr\'edire des valeurs de temp\'erature et de gravit\'e de surface par le biais de r\'egression. Une panoplie d'autres applications de \textit{data mining} en astronomie sont discut\'ees par \cite{ball2010data}.

\section{R√©partition et remerciements}

La s\'eparation des t\^aches dans le projet a \'et\'e \'equitable. Tous les auteurs ont particip\'es conjointement \`a l'\'elaboration des algorithmes ainsi qu'\`a la r\'edaction du pr\'esent rapport. Nous voudrions remercier Tegan Maharaj et Chehib Trabelsi pour nous avoir orient\'e vers les donn\'ees du \textit{PhysioNet/Computing in Cardiology Challenge 2017}.


\small
\bibliographystyle{apalike}
\bibliography{report}

\clearpage
\section*{Annexe}

<<<<<<< HEAD
\subsection{Tables}

\begin{table*}[h!]
  \caption{Taux de classification obtenu avec l'algorithme SVM pour les trois noyaux √©tudi√©s avec utilisation du PCA avec les 300 premi√®res composantes principales conserv√©es dans le pr√©traitement des donn√©es pour l'ensemble de donn√©es d'√©lectrocardiogrammes.}
  \vspace{0.2cm}
  \label{tab:ecg_pca_300}
  \centering
  \begin{tabular}{lllllll}
    \toprule
     & \multicolumn{3}{c}{\sc{Ens. d'entra√Ænement}} & \multicolumn{3}{c}{\sc{Ens. de validation}}\\
    \sc{Noyau} & $C=0.75$ & $C=1.0$ & $C=1.25$ & $C=0.75$ & $C=1.0$ & $C=1.25$ \\
    \midrule
    RBF          & 86.51\% & 95.62\% & 98.03\% & 58.97\% & 58.55\% & 58.48\% \\
    Poly. deg. 2 & 93.56\% & 95.34\% & 96.13\% & 53.91\% & 53.48\% & 53.55\% \\
    Poly. deg. 3 & 99.70\% & 99.88\% & 99.89\% & 55.03\% & 55.17\% & 54.54\% \\
    \bottomrule
  \end{tabular}
\end{table*}

\begin{table*}[h!]
  \caption{Taux de classification obtenu avec l'algorithme SVM pour les trois noyaux √©tudi√©s avec utilisation du PCA avec les 100 premi√®res composantes principales conserv√©es dans le pr√©traitement des donn√©es pour l'ensemble de donn√©es d'√©lectrocardiogrammes.}
  \vspace{0.2cm}
  \label{tab:ecg_pca_100}
  \centering
  \begin{tabular}{lllllll}
    \toprule
     & \multicolumn{3}{c}{\sc{Ens. d'entra√Ænement}} & \multicolumn{3}{c}{\sc{Ens. de validation}}\\
    \sc{Noyau} & $C=0.75$ & $C=1.0$ & $C=1.25$ & $C=0.75$ & $C=1.0$ & $C=1.25$ \\
    \midrule
    RBF          & 97.98\% & 99.63\% & 99.86\% & 59.11\% & 58.34\% & 58.90\% \\
    Poly. deg. 2 & 91.05\% & 92.42\% & 93.77\% & 52.99\% & 53.41\% & 53.55\% \\
    Poly. deg. 3 & 99.98\% & 99.98\% & 99.98\% & 52.15\% & 52.01\% & 51.58\% \\
    \bottomrule
  \end{tabular}
\end{table*}

\begin{table*}[h!]
  \caption{Taux de classification obtenu avec l'algorithme SVM pour les trois noyaux √©tudi√©s avec l'utilisation d'une transform√©e de Fourier lors du pr√©traitment des donn√©es pour l'ensemble de donn√©es d'√©lectrocardiogrammes.}
  \vspace{0.2cm}
  \label{tab:ecg_fourier}
  \centering
  \begin{tabular}{lllllll}
    \toprule
     & \multicolumn{3}{c}{\sc{Ens. d'entra√Ænement}} & \multicolumn{3}{c}{\sc{Ens. de validation}}\\
    \sc{Noyau} & $C=0.5$ & $C=1.0$ & $C=1.5$ & $C=0.5$ & $C=1.0$ & $C=1.5$ \\
    \midrule
    RBF          & 59.54\% & 100.00\% & 100.00\% & 58.90\% & 58.90\% & 58.90\% \\
    Poly. deg. 2 & 100.00\% & 100.00\% & 100.00\% & 55.52\% & 55.52\% & 55.52\% \\
    Poly. deg. 3 & 100.00\% & 100.00\% & 100.00\% & 59.68\% & 54.40\% & 54.40\% \\
    \bottomrule
  \end{tabular}
\end{table*}

\begin{table*}[h!]
  \caption{Taux de classification en fonction du nombre de convolutions dans le r√©seau de neurones convolutionnel pour les donn√©es d'√©lectrocardiogramme.}
  \vspace{0.2cm}
  \label{tab:n_conv_ecg}
  \centering
  \begin{tabular}{lll}
    \toprule
    \sc{Config.} & \sc{Ens. d'entra√Ænement} & \sc{Ens. de validation} \\
    \midrule
    $[100]$          & 79.62\% & 68.82\% \\
    $[50, 100]$      & 79.17\% & 74.76\% \\
    $[10, 50, 100]$     & 79.22\% & 76.72\%\\
    $[10, 50, 100, 200]$ & 81.98\% & 77.92\% \\
    \bottomrule
  \end{tabular}
\end{table*}

\begin{table*}[h!]
  \caption{Taux de classification obtenu avec l'algorithme DNN pour l'ensemble de donn√©es SDSS pour diff√©rentes architectures.}
  \vspace{0.2cm}
  \label{tab:sdss_dnn_arch}
  \centering
  \begin{tabular}{lll}
    \toprule
    \sc{Config.} & \sc{Ens. d'entra√Ænement} & \sc{Ens. de validation} \\
    \midrule
    $[50]$           & 97.32\% & 93.93\% \\
    $[100]$          & 97.74\% & 93.89\% \\
    $[200]$          & 95.53\% & 93.93\% \\
    $[400]$          & 97.78\% & 93.96\% \\
    $[200, 100]$     & 97.83\% & 94.39\% \\
    $[200, 50]$      & 97.15\% & 94.37\% \\
    $[500, 100]$     & 97.91\% & 94.36\% \\
    $[150, 100, 50]$ & 97.92\% & 94.56\% \\
    $[500, 100, 50]$ & 98.12\% & 94.31\% \\
    \bottomrule
  \end{tabular}
\end{table*}

\begin{table*}[h!]
  \caption{Taux de classification obtenu avec l'algorithme DNN pour l'ensemble de donn√©es SDSS en fonction de la taille des lots pour l'architecture [150, 100, 50].}
  \vspace{0.2cm}
  \label{tab:sdss_dnn_batch}
  \centering
  \begin{tabular}{lll}
    \toprule
    \sc{Batch size} & \sc{Ens. d'entra√Ænement} & \sc{Ens. de validation} \\
    \midrule
    5           & 96.84\% & 94.31\% \\
    50          & 97.29\% & 94.08\% \\
    500         & 97.94\% & 94.41\% \\
    \bottomrule
  \end{tabular}
\end{table*}

%cnn sdss

\begin{table*}[h!]
  \caption{Taux de classification obtenu avec l'algorithme CNN pour l'ensemble de donn√©es SDSS en fonction du nombre de filtres de convolution par couche de convolution.}
  \vspace{0.2cm}
  \label{tab:sdss_cnn_conv}
  \centering
  \begin{tabular}{lll}
    \toprule
    \sc{Config.} & \sc{Ens. d'entra√Ænement} & \sc{Ens. de validation} \\
    \midrule
    $[10]$          & 97.41\% & 93.75\% \\
    $[50]$          & 99.02\% & 94.23\% \\
    $[100]$         & 98.62\% & 94.47\% \\
    $[10, 50]$      & 96.00\% & 94.57\% \\
    $[50, 100]$     & 98.96\% & 94.40\% \\
    $[10, 50, 100]$ & 97.41\% & 94.55\% \\
    \bottomrule
  \end{tabular}
\end{table*}

\begin{table*}[h!]
  \caption{Taux de classification obtenu avec l'algorithme CNN pour l'ensemble de donn√©es SDSS en fonction de la taille des lots.}
  \vspace{0.2cm}
  \label{tab:sdss_cnn_bs}
  \centering
  \begin{tabular}{lll}
    \toprule
    \sc{Batch size} & \sc{Ens. d'entra√Ænement} & \sc{Ens. de validation} \\
    \midrule
    5     & 94.75\% & 94.13\% \\
    50    & 94.42\% & 94.40\% \\
    500   & 95.77\% & 94.31\% \\
    \bottomrule
  \end{tabular}
\end{table*}

\begin{table*}[h!]
  \caption{Taux de classification obtenu avec l'algorithme CNN pour l'ensemble de donn√©es SDSS en fonction de l'architecture du r√©seau √† la sortie du CNN.}
  \vspace{0.2cm}
  \label{tab:sdss_cnn_dnn}
  \centering
  \begin{tabular}{lll}
    \toprule
    \sc{Config.} & \sc{Ens. d'entra√Ænement} & \sc{Ens. de validation} \\
    \midrule
    $[20]$          & 95.91\% & 94.25\% \\
    $[50]$          & 96.26\% & 94.36\% \\
    $[100]$         & 98.02\% & 94.27\% \\
    $[20, 50]$      & 95.79\% & 94.04\% \\
    $[50, 100]$     & 97.68\% & 94.29\% \\
    $[20, 50, 100]$ & 94.35\% & 94.07\% \\
    \bottomrule
  \end{tabular}
\end{table*}


\FloatBarrier
\subsection{Figures}
%svm ecg



\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.77\textwidth]{figures/ecg_constant.png}
\caption{Taux de classification sur les donn√©es d'√©lectrocardiogramme en fonction de la constante de p√©nalit√© C pour l'algorithme SVM \`a noyau polynomial de degr\'e 2 avec des donn√©es transform√©es √† l'aide d'une transform√©e de Fourier. }
\label{fig:ecg_val_c}
\end{center}
\end{figure}


% dnn ecg

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.77\textwidth]{figures/ecg_dnn_train.png}
\caption{Taux de classification sur les donn√©es d'√©lectrocardiogramme en fonction du nombre d'√©poques d'entra√Ænement pour le r√©seau de neurones de type MLP avec deux couches cach√©es de 250 et 100 neurones, respectivement. }
\label{fig:ecg_dnn_train}
\end{center}
\end{figure}

% cnn ecg



%svm sdss



%mlp sdss



\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.77\textwidth]{figures/sdss_svm_c.png}
\caption{Taux de classification sur les donn√©es de SDSS en fonction de la constante de p√©nalit√© C pour l'algorithme SVM \`a noyau RBF. }
\label{fig:sdss_svm_c}
\end{center}
\end{figure}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.77\textwidth]{figures/sdss_dnn_reg.png}
\caption{Taux de classification sur les donn√©es de SDSS en fonction des param\`etres et du type de r\'egularisation pour l'algorithme MLP. }
\label{fig:sdss_dnn_reg}
\end{center}
\end{figure}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.77\textwidth]{figures/sdss_dnn_train.png}
\caption{Taux de classification sur les donn√©es de SDSS en fonction du nombre d'√©poques d'entra√Ænement pour le r√©seau de neurones de type MLP.}
\label{fig:sdss_dnn_train}
\end{center}
\end{figure}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.77\textwidth]{figures/sdss_cnn_train.png}
\caption{Taux de classification sur les donn√©es de SDSS en fonction du nombre d'√©poques d'entra√Ænement pour le r√©seau de neurones convolutif. }
\label{fig:sdss_cnn_train}
\end{center}
\end{figure}



=======
>>>>>>> 6621b0a5e70dc31ef4f0aaecb19bd4515b78d55b
\end{document}